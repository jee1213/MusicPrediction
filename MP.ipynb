{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import Perceptron\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the task is to categorize user given info (bd, city, registered_via, registration duration) \n",
    "# and songs (via language, genre_ids, )... such that the later given user can be categorized and \n",
    "# we can predict whether the user will like a given song or not.\n",
    "# One can choose to output predict_proba() for individual classifier and read out probability to be\n",
    "# classifies as 1 (=replay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "songs = pd.read_csv('songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(len(train))\n",
    "#print(len(test))\n",
    "#len(train[train.index.duplicated(keep=False)])\n",
    "# train has no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = pd.read_csv('members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's fill up \"bd\" from user data alone. #\n",
    "user_num = user.drop('msno',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id = user['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train['bd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_num.loc[(user_num['gender'].isnull()),'gender']=0\n",
    "user_num['gender'] = user_num['gender'].map({0:0,'female':1,'male':2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr,pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_num.loc[(user_num['bd']<0)|(user_num['bd']>100),'bd']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's convert this into day of year and year\n",
    "user_num['expiration_date'] = pd.to_datetime(user_num['expiration_date'],format='%Y%m%d')\n",
    "user_num['exp_year'] = user_num['expiration_date'].dt.year.astype(int)\n",
    "user_num['exp_doy'] = user_num['expiration_date'].dt.dayofyear.astype(int)\n",
    "user_num= user_num.drop('expiration_date',axis=1)\n",
    "user_num['registration_init_time'] = pd.to_datetime(user_num['registration_init_time'],format='%Y%m%d')\n",
    "user_num['reg_year'] = user_num['registration_init_time'].dt.year.astype(int)\n",
    "user_num['reg_doy'] = user_num['registration_init_time'].dt.dayofyear.astype(int)\n",
    "user_num = user_num.drop('registration_init_time',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.060697900431217984, pvalue=1.8826363771224628e-29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(user_num['bd'],user_num['exp_doy'])\n",
    "#pearsonr(user_num['registration_init_time'],user_num['expiration_date'])\n",
    "#city:0.7847 / 0.5461\n",
    "#gender:0.8713 /0.691\n",
    "#registered_via:0.2274 /0.2266\n",
    "#reg_init_time:-0.5262 / -0.452\n",
    "#expiration_date:0.3371 / 0.119\n",
    "# pearsonr and spearmanr has similar correlation values.\n",
    "# let's drop gender\n",
    "# let's predict bd based on other user data (#registration_init_time, registered_via and expiration_date)\n",
    "# we use decision tree algorithm to fill in the missing bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_fill = user_num.drop('city',axis=1)\n",
    "user_bd_fill = user_bd_fill.drop('gender',axis=1)\n",
    "user_bd = user_bd_fill['bd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_null = user_bd_fill.loc[user_bd_fill['bd']==0]\n",
    "user_bd_null = user_bd_null.drop('bd',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_train = user_bd_fill.loc[user_bd_fill['bd']!=0]\n",
    "Xuser_bd_train = user_bd_train.drop('bd',axis=1)\n",
    "Yuser_bd_train = user_bd_train['bd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.88\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(Xuser_bd_train, Yuser_bd_train)\n",
    "Y_pred = decision_tree.predict(user_bd_null)\n",
    "acc_decision_tree = round(decision_tree.score(Xuser_bd_train, Yuser_bd_train) * 100, 2)\n",
    "print(acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_null['bd'] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bd_fill = pd.concat([user_bd_null,user_bd_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these can be used as cross validation set\n",
    "user_bd_drop=user_num[user_num.bd!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bd_fill['msno'] = user['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_info = pd.read_csv('song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(train,user_bd_fill,on='msno',how='left')\n",
    "df_test = pd.merge(test,user_bd_fill,on='msno',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_mg = pd.merge(songs,song_info,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train,song_mg,on='song_id',how='left')\n",
    "df_test = pd.merge(df_test,song_mg,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.loc[(df_train['bd']<0)|(df_train['bd']>100),'bd']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train does not miss an index. How did missing index happen in tidy_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gender does not correlate much with othervariable : cannot be filled\n",
    "user_gender_drop =  user_num[user_num.gender!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.01446214719150264, pvalue=0.081600505983868893)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(user_gender_drop['gender'],user_gender_drop['reg_year'])\n",
    "#bd-registered_via 0.2258\n",
    "#bd-registration_init_time -0.332\n",
    "#bd-expiration_date 0.128\n",
    "# gender does not have significant correlation to any of the variables: we can drop gender? should we check it against song variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(df_train['bd'])\n",
    "# too many unknown bds : about 40 % : instead of dropping them, find correlation and fill them in!\n",
    "# e.g. registered_via, registration_init_time, expiration_date-registration_init_time\n",
    "# is it different from including them in the training data separately?\n",
    "# it is, because it may induce false correlation if we simply decide all the unknown bds are 0s #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(user_bd_fill['bd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.loc[(df_train['gender'].isnull()),'gender']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train['gender'] = df_train['gender'].map({0:0,'female':1,'male':2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test['genre_ids'].isnull(),'genre_ids']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.loc[df_train['genre_ids'].isnull(),'genre_ids']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a fast way to split elements with given (esp unusual) delimeter\n",
    "def tidy_split(df, column, sep='|', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train[['genre1','genre2','genre3']] = df_train['genre_ids'].apply(lambda x: pd.Series(x.split('|')))\n",
    "#df_train[['genre_id']] = pd.DataFrame(df_train['genre_ids'].str.split('|').tolist()).head()\n",
    "df_train= tidy_split(df_train, 'genre_ids', sep='|')\n",
    "df_test= tidy_split(df_test, 'genre_ids', sep='|')\n",
    "# we will train the models, using all the duplicates\n",
    "# then we can average the target likelihood of duplicates to estimate the final target probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the duplicated index to dataframe\n",
    "test_idx = pd.DataFrame(df_test.index)\n",
    "train_idx = pd.DataFrame(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check what variable correlates with genre_ids\n",
    "#plt.scatter(df_train['bd'],df_train['registered_via'])\n",
    "#pd.crosstab(df_train['genre_cut'],df_train['gender'],normalize='columns')\n",
    "#spearmanr(df_train['genre_ids'],df_train['gender'])\n",
    "#somehow this correlation calculation (and crosstab) never finishes#\n",
    "#is it because it is too big?#\n",
    "# bd does play a role in preferred genre # song_length, language (a bit)\n",
    "# expiration_date does!!! WHY????\n",
    "# registered_via does a little\n",
    "# city does a littel too\n",
    "# registration_init_time not much\n",
    "# gender does not seem to #\n",
    "# are these gender - genre correlation at any statistical significance? how can I tell that? what is the standard deviation? #\n",
    "# for some genres, mixed gender fraction is significantly outside either one of the gender: does it mean it is small number stats#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# are song language and user city strongly correlated? - some exclusions do exist\n",
    "# is there a language strongly preferred in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_id = df_train['msno']\n",
    "test_id = df_test['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop('msno',axis=1)\n",
    "X_test = df_test.drop('msno',axis=1)\n",
    "X_train = X_train.drop('target',axis=1)\n",
    "X_combined = [X_train,X_test]\n",
    "X_train = X_train.drop('lyricist',axis=1)\n",
    "X_train = X_train.drop('composer',axis=1)\n",
    "X_train = X_train.drop('artist_name',axis=1)\n",
    "X_train = X_train.drop('song_id',axis=1)\n",
    "X_train = X_train.drop('name',axis=1)\n",
    "X_train = X_train.drop('isrc',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X_test.drop('lyricist',axis=1)\n",
    "X_test = X_test.drop('composer',axis=1)\n",
    "X_test = X_test.drop('artist_name',axis=1)\n",
    "X_test = X_test.drop('song_id',axis=1)\n",
    "X_test = X_test.drop('name',axis=1)\n",
    "X_test = X_test.drop('isrc',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.loc[X_train['language'].isnull(),'language']=0\n",
    "X_test.loc[X_test['language'].isnull(),'language']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = X_test['id']\n",
    "X_test = X_test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = pd.DataFrame(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.loc[X_train['source_system_tab'].isnull(),'source_system_tab']=0\n",
    "X_train.loc[X_train['source_screen_name'].isnull(),'source_screen_name']=0\n",
    "X_train.loc[X_train['source_type'].isnull(),'source_type']=0\n",
    "X_train.loc[X_train['song_length'].isnull(),'song_length']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.loc[X_test['source_system_tab'].isnull(),'source_system_tab']=0\n",
    "X_test.loc[X_test['source_screen_name'].isnull(),'source_screen_name']=0\n",
    "X_test.loc[X_test['source_type'].isnull(),'source_type']=0\n",
    "X_test.loc[X_test['song_length'].isnull(),'song_length']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test.loc[X_test['genre_ids'].isnull(),'genre_ids']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tgt = pd.concat([X_train,X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tgt = pd.get_dummies(X_tgt,columns=['source_system_tab','source_screen_name','source_type']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_tgt[:n_train]\n",
    "X_test = X_tgt[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2705361"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bd</th>\n",
       "      <th>exp_doy</th>\n",
       "      <th>exp_year</th>\n",
       "      <th>reg_doy</th>\n",
       "      <th>reg_year</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>language</th>\n",
       "      <th>source_system_tab_0</th>\n",
       "      <th>...</th>\n",
       "      <th>source_type_listen-with</th>\n",
       "      <th>source_type_local-library</th>\n",
       "      <th>source_type_local-playlist</th>\n",
       "      <th>source_type_my-daily-playlist</th>\n",
       "      <th>source_type_online-playlist</th>\n",
       "      <th>source_type_radio</th>\n",
       "      <th>source_type_song</th>\n",
       "      <th>source_type_song-based-playlist</th>\n",
       "      <th>source_type_top-hits-for-artist</th>\n",
       "      <th>source_type_topic-article-playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>261</td>\n",
       "      <td>2017</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>224130</td>\n",
       "      <td>458</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>261</td>\n",
       "      <td>2017</td>\n",
       "      <td>50</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>320470</td>\n",
       "      <td>465</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>329</td>\n",
       "      <td>2016</td>\n",
       "      <td>322</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>315899</td>\n",
       "      <td>2022</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>2017</td>\n",
       "      <td>206</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>285210</td>\n",
       "      <td>465</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>2017</td>\n",
       "      <td>206</td>\n",
       "      <td>2007</td>\n",
       "      <td>9</td>\n",
       "      <td>197590</td>\n",
       "      <td>873</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bd  exp_doy  exp_year  reg_doy  reg_year  registered_via  song_length  \\\n",
       "0  19      261      2017       50      2016               7       224130   \n",
       "1  19      261      2017       50      2016               7       320470   \n",
       "2  38      329      2016      322      2016               4       315899   \n",
       "3  30      120      2017      206      2007               9       285210   \n",
       "4  30      120      2017      206      2007               9       197590   \n",
       "\n",
       "   genre_ids  language  source_system_tab_0  \\\n",
       "0        458         3                    0   \n",
       "1        465         3                    0   \n",
       "2       2022        17                    0   \n",
       "3        465        52                    0   \n",
       "4        873        -1                    0   \n",
       "\n",
       "                  ...                  source_type_listen-with  \\\n",
       "0                 ...                                        0   \n",
       "1                 ...                                        0   \n",
       "2                 ...                                        0   \n",
       "3                 ...                                        0   \n",
       "4                 ...                                        0   \n",
       "\n",
       "   source_type_local-library  source_type_local-playlist  \\\n",
       "0                          1                           0   \n",
       "1                          1                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   source_type_my-daily-playlist  source_type_online-playlist  \\\n",
       "0                              0                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "\n",
       "   source_type_radio  source_type_song  source_type_song-based-playlist  \\\n",
       "0                  0                 0                                0   \n",
       "1                  0                 0                                0   \n",
       "2                  0                 0                                1   \n",
       "3                  1                 0                                0   \n",
       "4                  1                 0                                0   \n",
       "\n",
       "   source_type_top-hits-for-artist  source_type_topic-article-playlist  \n",
       "0                                0                                   0  \n",
       "1                                0                                   0  \n",
       "2                                0                                   0  \n",
       "3                                0                                   0  \n",
       "4                                0                                   0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#decision_tree = DecisionTreeClassifier(max_depth=20)\n",
    "#decision_tree.fit(X_train, Y_train)\n",
    "#acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "#print (acc_decision_tree)\n",
    "# depth 20 tree performs better than 10!\n",
    "# implement another algorithm to do the ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ijee/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.73\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=20, max_depth=30)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "#Y_pred = clf.predict(X_test)\n",
    "#print clf.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "print (acc_random_forest)\n",
    "# accuracy too high : indicates that it has high variance (overfitting) problem. \n",
    "# Remember even the best models in the competition performs about 70 % success on the test dataset.\n",
    "# best performance so far : RF w/ depth 30 est 20 (minor improvement over depth 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.705361e+06</td>\n",
       "      <td>2.705361e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.375910e-01</td>\n",
       "      <td>4.624090e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.815491e-01</td>\n",
       "      <td>1.815491e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.968669e-01</td>\n",
       "      <td>3.377914e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.404358e-01</td>\n",
       "      <td>4.595642e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.622086e-01</td>\n",
       "      <td>6.031331e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "count  2.705361e+06  2.705361e+06\n",
       "mean   5.375910e-01  4.624090e-01\n",
       "std    1.815491e-01  1.815491e-01\n",
       "min    0.000000e+00  0.000000e+00\n",
       "25%    3.968669e-01  3.377914e-01\n",
       "50%    5.404358e-01  4.595642e-01\n",
       "75%    6.622086e-01  6.031331e-01\n",
       "max    1.000000e+00  1.000000e+00"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = pd.DataFrame(Y_pred)\n",
    "Y_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred['index'] = test_idx\n",
    "Y_pred = Y_pred.groupby('index').mean()\n",
    "#Y_pred = Y_pred[~Y_pred.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify this such that it won't discard, but average, the duplicates\n",
    "#df_train = df_train[~df_train.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify this such that it won't discard, but average, the duplicates\n",
    "#df_test = df_test[~df_test.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "            \"id\": test_id,\n",
    "                    \"target\": Y_pred.iloc[:,1]\n",
    "                        })\n",
    "submission = submission.groupby('id').mean().reset_index()\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(test) !=len(submission):\n",
    "    print('something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
