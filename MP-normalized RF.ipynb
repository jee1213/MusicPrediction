{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the task is to categorize user given info (bd, city, registered_via, registration duration) \n",
    "# and songs (via language, genre_ids, )... such that the later given user can be categorized and \n",
    "# we can predict whether the user will like a given song or not.\n",
    "# One can choose to output predict_proba() for individual classifier and read out probability to be\n",
    "# classifies as 1 (=replay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "songs = pd.read_csv('songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = pd.read_csv('members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's fill up \"bd\" from user data alone. #\n",
    "user_num = user.drop('msno',axis=1)\n",
    "user_num = user_num.drop('registered_via',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id = user['msno']\n",
    "user_reg = user['registered_via']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train['bd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_num.loc[(user_num['gender'].isnull()),'gender']=0\n",
    "#user_num['gender'] = user_num['gender'].map({0:0,'female':1,'male':2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr,pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_num.loc[(user_num['bd']<0)|(user_num['bd']>100),'bd']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's convert this into day of year and year\n",
    "user_num['expiration_date'] = pd.to_datetime(user_num['expiration_date'],format='%Y%m%d')\n",
    "user_num['exp_year'] = user_num['expiration_date'].dt.year.astype(int)\n",
    "user_num['exp_doy'] = user_num['expiration_date'].dt.dayofyear.astype(int)\n",
    "user_num= user_num.drop('expiration_date',axis=1)\n",
    "user_num['registration_init_time'] = pd.to_datetime(user_num['registration_init_time'],format='%Y%m%d')\n",
    "user_num['reg_year'] = user_num['registration_init_time'].dt.year.astype(int)\n",
    "user_num['reg_doy'] = user_num['registration_init_time'].dt.dayofyear.astype(int)\n",
    "user_num = user_num.drop('registration_init_time',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.060697900431217984, pvalue=1.8826363771224628e-29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(user_num['bd'],user_num['exp_doy'])\n",
    "#pearsonr(user_num['registration_init_time'],user_num['expiration_date'])\n",
    "#city:0.7847 / 0.5461\n",
    "#gender:0.8713 /0.691\n",
    "#registered_via:0.2274 /0.2266\n",
    "#reg_init_time:-0.5262 / -0.452\n",
    "#expiration_date:0.3371 / 0.119\n",
    "# pearsonr and spearmanr has similar correlation values.\n",
    "# let's drop gender\n",
    "# let's predict bd based on other user data (#registration_init_time, registered_via and expiration_date)\n",
    "# we use decision tree algorithm to fill in the missing bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_fill = user_num.drop('city',axis=1)\n",
    "user_bd_fill = user_bd_fill.drop('gender',axis=1)\n",
    "user_bd = user_bd_fill['bd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_null = user_bd_fill.loc[user_bd_fill['bd']==0]\n",
    "user_bd_null = user_bd_null.drop('bd',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_train = user_bd_fill.loc[user_bd_fill['bd']!=0]\n",
    "Xuser_bd_train = user_bd_train.drop('bd',axis=1)\n",
    "Yuser_bd_train = user_bd_train['bd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's normalize the user variables here.\n",
    "#user_bd_fill.head(5)\n",
    "scale = np.std(Xuser_bd_train)\n",
    "Xuser_bd_train /= scale\n",
    "user_bd_null /= scale \n",
    "mean = np.mean(Xuser_bd_train)\n",
    "Xuser_bd_train -= mean\n",
    "user_bd_null -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xuser_bd_train['registered_via'] = user.loc[user_bd_fill['bd']!=0,'registered_via']\n",
    "user_bd_null['registered_via'] = user.loc[user_bd_fill['bd']==0,'registered_via']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp_year          False\n",
       "exp_doy           False\n",
       "reg_year          False\n",
       "reg_doy           False\n",
       "registered_via    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xuser_bd_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.88\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(Xuser_bd_train, Yuser_bd_train)\n",
    "Y_pred = decision_tree.predict(user_bd_null)\n",
    "acc_decision_tree = round(decision_tree.score(Xuser_bd_train, Yuser_bd_train) * 100, 2)\n",
    "print(acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_null['bd'] = Y_pred\n",
    "Xuser_bd_train['bd']= Yuser_bd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bd_fill = pd.concat([user_bd_null,Xuser_bd_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34403"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_bd_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_bd_fill = user_bd_fill.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bd_fill['msno'] = user['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#song_info = pd.read_csv('song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we are not going to use additional song_info.\n",
    "#songs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's drop unnecessary columns before merging, to save computational resources\n",
    "songs = songs.drop('lyricist',axis=1)\n",
    "songs = songs.drop('composer',axis=1)\n",
    "songs = songs.drop('artist_name',axis=1)\n",
    "songs = songs.drop('song_length',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale = np.std(songs['song_length'])\n",
    "#songs['song_length'] /= scale\n",
    "#mean = np.mean(songs['song_length'])\n",
    "#songs['song_length'] -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(train,user_bd_fill,on='msno',how='left')\n",
    "df_test = pd.merge(test,user_bd_fill,on='msno',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#song_mg = pd.merge(songs,song_info,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train,songs,on='song_id',how='left')\n",
    "df_test = pd.merge(df_test,songs,on='song_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2556790"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.loc[(df_train['bd']<0)|(df_train['bd']>100),'bd']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train does not miss an index. How did missing index happen in tidy_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gender does not correlate much with othervariable : cannot be filled\n",
    "#user_gender_drop =  user_num[user_num.gender!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#spearmanr(user_gender_drop['gender'],user_gender_drop['reg_year'])\n",
    "#bd-registered_via 0.2258\n",
    "#bd-registration_init_time -0.332\n",
    "#bd-expiration_date 0.128\n",
    "# gender does not have significant correlation to any of the variables: we can drop gender? should we check it against song variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(df_train['bd'])\n",
    "# too many unknown bds : about 40 % : instead of dropping them, find correlation and fill them in!\n",
    "# e.g. registered_via, registration_init_time, expiration_date-registration_init_time\n",
    "# is it different from including them in the training data separately?\n",
    "# it is, because it may induce false correlation if we simply decide all the unknown bds are 0s #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(user_bd_fill['bd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.loc[(df_train['gender'].isnull()),'gender']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train['gender'] = df_train['gender'].map({0:0,'female':1,'male':2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test['genre_ids'].isnull(),'genre_ids']=0\n",
    "df_train.loc[df_train['genre_ids'].isnull(),'genre_ids']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a fast way to split elements with given (esp unusual) delimeter\n",
    "def tidy_split(df, column, sep='|', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train[['genre1','genre2','genre3']] = df_train['genre_ids'].apply(lambda x: pd.Series(x.split('|')))\n",
    "#df_train[['genre_id']] = pd.DataFrame(df_train['genre_ids'].str.split('|').tolist()).head()\n",
    "df_train= tidy_split(df_train, 'genre_ids', sep='|')\n",
    "df_test= tidy_split(df_test, 'genre_ids', sep='|')\n",
    "# we will train the models, using all the duplicates\n",
    "# then we can average the target likelihood of duplicates to estimate the final target probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# genre_ids should not be normalized, as it is categorical and not continuous variable\n",
    "#df_train['genre_ids']=df_train['genre_ids'].astype(int)\n",
    "#df_test['genre_ids']=df_test['genre_ids'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scale = np.std(df_train['genre_ids'])\n",
    "#df_train['genre_ids'] /= scale\n",
    "#df_test['genre_ids'] /= scale\n",
    "#mean = np.mean(df_train['genre_ids'])\n",
    "#df_train['genre_ids'] -= mean\n",
    "#df_test['genre_ids'] -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the duplicated index to dataframe\n",
    "test_idx = pd.DataFrame(df_test.index)\n",
    "train_idx = pd.DataFrame(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check what variable correlates with genre_ids\n",
    "#plt.scatter(df_train['bd'],df_train['registered_via'])\n",
    "#pd.crosstab(df_train['genre_cut'],df_train['gender'],normalize='columns')\n",
    "#spearmanr(df_train['genre_ids'],df_train['gender'])\n",
    "#somehow this correlation calculation (and crosstab) never finishes#\n",
    "#is it because it is too big?#\n",
    "# bd does play a role in preferred genre # song_length, language (a bit)\n",
    "# expiration_date does!!! WHY????\n",
    "# registered_via does a little\n",
    "# city does a littel too\n",
    "# registration_init_time not much\n",
    "# gender does not seem to #\n",
    "# are these gender - genre correlation at any statistical significance? how can I tell that? what is the standard deviation? #\n",
    "# for some genres, mixed gender fraction is significantly outside either one of the gender: does it mean it is small number stats#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# are song language and user city strongly correlated? - some exclusions do exist\n",
    "# is there a language strongly preferred in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_id = df_train['msno']\n",
    "test_id = df_test['msno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2705361"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop('msno',axis=1)\n",
    "X_test = df_test.drop('msno',axis=1)\n",
    "X_train = X_train.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop('song_id',axis=1)\n",
    "X_test = X_test.drop('song_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.loc[X_train['language'].isnull(),'language']=0\n",
    "X_test.loc[X_test['language'].isnull(),'language']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = X_test['id']\n",
    "X_test = X_test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = pd.DataFrame(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.loc[X_train['source_system_tab'].isnull(),'source_system_tab']=0\n",
    "X_train.loc[X_train['source_screen_name'].isnull(),'source_screen_name']=0\n",
    "X_train.loc[X_train['source_type'].isnull(),'source_type']=0\n",
    "#X_train.loc[X_train['song_length'].isnull(),'song_length']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.loc[X_test['source_system_tab'].isnull(),'source_system_tab']=0\n",
    "X_test.loc[X_test['source_screen_name'].isnull(),'source_screen_name']=0\n",
    "X_test.loc[X_test['source_type'].isnull(),'source_type']=0\n",
    "#X_test.loc[X_test['song_length'].isnull(),'song_length']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test.loc[X_test['genre_ids'].isnull(),'genre_ids']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tgt = pd.concat([X_train,X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tgt['src_sys_tab'] = pd.factorize(X_tgt['source_system_tab'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tgt = X_tgt.drop('source_system_tab',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tgt['src_scr_nm'] = pd.factorize(X_tgt['source_screen_name'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tgt = X_tgt.drop('source_screen_name',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tgt['src_typ'] = pd.factorize(X_tgt['source_type'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tgt = X_tgt.drop('source_type',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.binary.BinaryEncoder(cols=['registered_via','genre_ids','language','src_sys_tab','src_scr_nm','src_typ'])\n",
    "X_tgt = encoder.fit_transform(X_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_tgt[:n_train]\n",
    "X_test = X_tgt[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ijee/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.01\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=10, max_depth=25)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "#Y_pred = clf.predict(X_test)\n",
    "#print clf.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "print (acc_random_forest)\n",
    "# accuracy too high : indicates that it has high variance (overfitting) problem. \n",
    "# Remember even the best models in the competition performs about 70 % success on the test dataset.\n",
    "# best performance so far : RF w/ depth 30 est 20, normalized (minor improvement over depth 20 / not normalized case)\n",
    "# now let's implement NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = pd.DataFrame(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred['index'] =test_idx\n",
    "Y_pred = Y_pred.groupby('index').mean()\n",
    "#Y_pred = Y_pred[~Y_pred.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify this such that it won't discard, but average, the duplicates\n",
    "#df_train = df_train[~df_train.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify this such that it won't discard, but average, the duplicates\n",
    "#df_test = df_test[~df_test.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "            \"id\": test_id,\n",
    "                    \"target\": Y_pred.iloc[:,1]\n",
    "                        })\n",
    "submission = submission.groupby('id').mean().reset_index()\n",
    "\n",
    "submission.to_csv('RFsubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if len(test) !=len(submission):\n",
    "#    print('something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
